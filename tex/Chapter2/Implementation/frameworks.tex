\documentclass{standalone}
\begin{document}
	
	\subsection{Frameworks}
	
	In order to perform all the necessary image processing operations both involving 2D and 3D filters, to perform the color quantization and to manage the input and output medical image format, I've used mainly two libraries for image processing and computer vision. These libraries has been written in C++ but has multi language support. I've performed all the 2D image processing operations like median blurring or filter application by using \textsc{OpenCV}~\cite{OpenCV}. For the managing of medical image formats, ensuring the preservation of voxel spatial information, and for the 3D operations, I've used \textsc{SimpleITK}.  To perform all the other operation on the image array, I've used \textsc{Numpy}~\cite{Numpy}.
	
	For the preliminary lung extraction, I've used the pre trained Unet available on GitHub(\url{https://github.com/JoHof/lungmask}).
	
	\subsubsection*{OpenCV} 
	
	\textsc{OpenCV}, acronym for Open Source Computer Vision, is an open source computer vision and machine learning software library. \textsc{OpenCV} was built to provide a common infrastructure for computer vision applications and to accelerate the use of machine perception in the commercial products. This library is implemented in C++, however bindings are available for \textsc{Python}, \textsc{Java} and \textsc{MATLAB/OCTAVE}. This library can use also hardware acceleration like Integrated Performance Primitives, and also  \textsc{CUDA} and  \textsc{OpenGL} based  \textsc{GPU} interfaces are available. 
	
	I've used the tolls from this library to perform all the processing that involves the single image and, most important, to perform the color quantization, since the k-means implementation offered by the library allows to cluster multi channel images in an efficient way.
	
	\subsubsection*{SimpleITK} 
	
	\textsc{SimpleITK} is a simplified programming interface to the algorithms and data structures of the Insight Toolkit ( \textsc{ITK}) that support many programming languages. The library provides a simplified interface to use Insight Tool Kit(ITK) library. 
	Insight Tool Kit (ITK) is an open source library which provides an extensive suite of tools for image analysis, developed since 1999 by US National Library of Medicine of the National Institutes of Health.This library provides tool useful to works also with N-dimensional images. 
	This library provides a powerful tools for the reading and writing of the image. Since \textsc{ITK}, ans so \textsc{SimpleITK},  consider the image like spatial object and not like arrays of values, it store also information about voxel spacing, size and origins, provided as well as the array, this makes us able to works only with the array by using \textsc{Numpy} or \textsc{OpenCV}, by preserving the spatial information of the image.
	
	\subsubsection*{Numpy}
	
	\textsc{Numpy} is an open source project aiming to enable numerical computing with Python. It was created in 2005, building on the early work of the Numerical and Numarray libraries.	\textsc{Numpy} is developed in the open on GitHub, through the consensus of the \textsc{Numpy} and wider scientific Python community.~\cite{Numpy}. 

	\subsubsection*{Pre-Trained UNet} 
	
	This network is a pre trained UNet which allows an Automated lung segmentation in CT under presence of severe pathologies. The whole code is written in python and it is based on torch and torchvision libraries. The repository offers 4 pre trained models for different kind of segmentation, like single lung lobe segmentation and the extraction of lung in presence of severe ILD. Each model perform the segmentation slice by slice. 
	
	The used network is a U-Net,that is a modification of the convolutional neural network architecture useful for medical and biological field, because is developed to works also with a small training dataset.
	The allowed pre-trained models are the follows : 
	\begin{itemize}
		\item \textbf{R231} : This model, trained on a dataset that cover a wide range of visual variability, performs a segmentation on individual slice and extract the right and left lung lobes including airpockets, tumor and effusion, wothout including the trachea.
		
		\item \textbf{LTRCLobes} : This model, trained on a subset of LTRC dataset, perform an individual segmentation fo lung lobes, but have limitad performances in case of severe ILD.
		
		\item \textbf{LTRCLobes\_R231} : Model which fuse the two previous one. Fills the false negative of LTCTLobes by using R231, but is computational expansive.
		
		\item \textbf{COVID231-Web} : Augmentation of R231 with COVID-19 slices that were mapped back from regular imaging formats to HU The data was collected and prepared by MedSeg. 
	\end{itemize}
		
	
	The network was trained in order to takes the maximum flexibility with respect of the field of view, in order to enable the segmentation without a prior localization of the organs.
	
	The model is trained on $231$ CT scans collected from PACS, selected following these criteria: 
	\begin{itemize}
		\item Random Sampling ($57$ scans)
		
		\item Sampling from Image Phenotypes (71 scans)
		
		\item Manual selection of edge cases : 
			\begin{itemize}
				\item Fibrosis ($28$ scans)
				
				\item Trauma ($20$ scans)
				
				\item Other Pathology ($55$)
				
			\end{itemize}
	\end{itemize}

	That ensure a proper variability of the training dataset.
	
	 The \textbf{COVID231-Web} was used developed to incorporates collections of slices and case reports from the web are often cropped, annotated or encoded in regular image formats so that the original hounsfield unit (HU) values can only be estimated.  Since the scans used in this works do not fall within these cases, we have used the the \textbf{R231} model, which works very well with COVID-19 CT.
	
	 
\end{document}