\documentclass{standalone}
\begin{document}
	\chapter*{kmeans clustering}\addcontentsline{toc}{chapter}{Appendix A - kmenas clustering}
	
	
	
	
	In this appendix I will describe the kmeans clustering algorithm, which is the one used for the computation of the centroids set, which corresponds to the characteristic color of each lung structure we wish to segment. \\
	Kmeans clustering is a clustering technique. Clustering technique are unsupervised classification technique which aims to divide data into non overlapping groups such that the data belonging to one group is similar to each other, but they are very distinct from data existing in the other groups~\cite{ART:Arshleen}~\cite{ART:Morisette}.\\ Since clustering techniques are unsupervised, aims to cluster by evaluating similarities and dissimilarities of intrinsic characteristics between clusters~\cite{ART:Morisette}, so no expected outcomes is given during method of learning~\cite{ART:Arshleen}.\\
	Kmeans clustering seek to assign each point to a particular cluster in a way that minimize the average square distance between points in the same cluster~\cite{Arthur2007}. A vector representing the mean is used to describe each cluster, so this technique is described as a centroid model~\cite{ART:Morisette}.Each point is assigned to the cluster with the nearest mean.\\
	
	Given an integer $k$ and a set of $n$ data points from $\mathbb{R}^d$, the kmeans clustering seek to find $k$ centers that minimize a potential function given by the sum of squares: 
	\begin{equation}
		\Phi = \sum_{x\in S}\min\| x - c\|^2
	\end{equation} 
	Where $S\subset \mathbb R^d$ is a set of points. In this work $\mathbb{R}^d$ is the colors space and $S$ is the space of color of each voxel.
	
	The steps of the algorithm are the following: 
	\begin{enumerate}
		\item Select the value of k as initial centroids
		\item Form k cluster by allocating every point to its most nearest centroid
		\item Recalculate the centroid for each cluster until the centroid does not change.

	\end{enumerate}
	
	Arthur and Vassilvitskii ~\cite{Arthur2007} have pointed that this algorithm is not accurate and can produce arbitrarily bad clusters. So they have developed a popular algorithm, the "kmeans++" which improves the clustering accuracy by made an accurate choice of the initial cluster centers.\\ 
	They pointed out that the bad clustering is caused to the fact that $\frac{\Phi}{\Phi_{opt}}$ is unbounded even if the number of clusters and points are fixed, where $\Phi_{opt}$ is the potential function in the optimal centroids case. They have proposed a variant for the choosing of the centroids, instead of chose the centroids randomly, the weight the initial points according to the distance square ($D(x)^2$) from the closest center already chosen. So the final algorithm is equal to the kmeans except for the intial centroids selection that is made as follows: 
	\begin{enumerate}
		\item Take one center $c_1$, chosen uniformly at random from $\Xi$.
		
		\item  Take a new center $c_i$, choosing $x \in \Xi$ with probability $\frac{D(x)^2}{\sum _{x \in \Xi} D(x)^2}$
		
		\item Repeat the step 2 till $k$ centers are choose
		
		\item Proceed like a classical kmeans clustering.
	
	\end{enumerate}

	This is the algorithm that we have used to found the characteristic color for the structure to segment. 
\end{document}